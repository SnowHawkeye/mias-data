{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Introduction to dimensionality reduction"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setup\n",
    "### Imports"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd                                     # for dataset manipulation (DataFrames)\n",
    "import numpy as np                                      # allows some mathematical operations\n",
    "import matplotlib.pyplot as plt                         # library used to display graphs\n",
    "import seaborn as sns                                   # more convenient visualisation library for dataframes\n",
    "import missingno as msno                                # utility library for missing values\n",
    "from sklearn.model_selection import train_test_split    # for classification\n",
    "from sklearn.neighbors import KNeighborsClassifier      # for classification\n",
    "from sklearn.decomposition import PCA                   # for Principal Component Analysis\n",
    "import time                                             # for execution time measurement"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Loading the dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fives = np.loadtxt(\"fives.txt\", delimiter=\",\")\n",
    "sixes = np.loadtxt(\"sixes.txt\", delimiter=\",\")\n",
    "\n",
    "# for practical reasons, we convert these arrays to a pandas dataframe\n",
    "df_fives = pd.DataFrame(fives)\n",
    "df_sixes = pd.DataFrame(sixes)\n",
    "\n",
    "# we also create a dataframe containing all numbers for later classification\n",
    "df_fives[\"number\"] = 5 # data labeling\n",
    "df_sixes[\"number\"] = 6 # data labeling\n",
    "df = pd.concat([df_fives, df_sixes], ignore_index=True)\n",
    "df_fives.drop(\"number\", inplace=True,axis=1)\n",
    "df_sixes.drop(\"number\", inplace=True,axis=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Utility functions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def show_image(row, title=\"\"):\n",
    "    \"\"\"This function takes a row of 256 pixels and displays it as a greyscale image\"\"\"\n",
    "    image = np.reshape(row, (16, 16))\n",
    "    plt.imshow(image, cmap=\"gray\")\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "def split_data(data):\n",
    "    X = data.drop(\"number\", axis=1)\n",
    "    y = data.number\n",
    "    return train_test_split(X, y,\n",
    "                            test_size=0.33,  # 10% of the data will be used for testing\n",
    "                            random_state=42,  # ensures reproducibility of the test\n",
    "                            stratify=y  # ensures the proportion of each class\n",
    "                            )\n",
    "\n",
    "def print_knn_score(scores, data_type=\"\"):\n",
    "    max_score = max(scores)\n",
    "    k_values_max_score = [i + 1 for i, v in enumerate(scores) if v == max_score]\n",
    "    print(f'Max {data_type} score {max_score * 100} % for k = {[i for i in k_values_max_score]}')\n",
    "\n",
    "def prediction_knn(data):\n",
    "    \"\"\" KNN-based classification for diabetes diagnosis. \"\"\"\n",
    "    X_train, X_test, y_train, y_test = split_data(data)\n",
    "    test_scores = []\n",
    "    train_scores = []\n",
    "\n",
    "    for k in range(1, 15):\n",
    "        knn = KNeighborsClassifier(k)\n",
    "        knn.fit(X_train, y_train)\n",
    "        train_scores.append(knn.score(X_train, y_train))  # \"score\" for KNN is the accuracy of the classification\n",
    "        test_scores.append(knn.score(X_test, y_test))\n",
    "\n",
    "    print_knn_score(train_scores, \"train\")\n",
    "    print_knn_score(test_scores, \"test\")\n",
    "\n",
    "def run_measure_time(function, **kwargs):\n",
    "    start_time = time.time()\n",
    "    function(**kwargs)\n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Baseline test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# equivalent to prediction_knn(data=df), but also measures time using our utility function\n",
    "run_measure_time(prediction_knn, data=df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Observing the dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "index = 9 # index of the image to show\n",
    "show_image(fives[index, :])\n",
    "show_image(sixes[index, :])\n",
    "# to do the same from a pandas dataframe\n",
    "print(\"Display from pandas:\")\n",
    "show_image(df_fives.iloc[index].to_numpy())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Using what you have learned in the previous lessons, examine the dataset and see what you can learn about it."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Visualisation example: the average numbers"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# The \"average\" number in the dataset\n",
    "show_image(df.drop(\"number\", axis=1).mean().to_numpy().reshape((16,16)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# The \"average\" 5\n",
    "show_image(df[df[\"number\"]==5].drop(\"number\", axis=1).mean().to_numpy().reshape((16,16)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# The \"average\" 6\n",
    "show_image(df[df[\"number\"]==6].drop(\"number\", axis=1).mean().to_numpy().reshape((16,16)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Visualisation example: pixel variance"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# display variance of each pixel: it shows which pixels are the most important in the dataset\n",
    "sns.heatmap(df.drop(\"number\", axis=1).var().to_numpy().reshape((16,16)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# same, but for 5's only\n",
    "sns.heatmap(df[df[\"number\"]==5].drop(\"number\", axis=1).var().to_numpy().reshape((16,16)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# same, but for 6's only\n",
    "sns.heatmap(df[df[\"number\"]==6].drop(\"number\", axis=1).var().to_numpy().reshape((16,16)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "*[Your comments here]*"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Principal Component Analysis (PCA)\n",
    "### Pre-processing\n",
    "\n",
    "When using PCA, it is necessary to standardize the data. Pixel values are already between -1 and 1, so we only need to center the data.\n",
    "Using what you have learned last time, center the data in `df_fives` and `df_sixes` respectively.\n",
    "\n",
    "*Hint: You can refer to the data preparation practical and use `sklearn`'s `StandardScaler`*.\n",
    "\n",
    "⚠️Centering means removing the mean value. You do not need to divide by the standard deviation. `sklearn`'s `StandardScaler`*, check its documentation to see how.\n",
    "⚠️Store the standardized data in new variables, because we will need the original data later.\n",
    "\n",
    "In fact, this step is not strictly necessary here, because we will use `sklearn`'s implementation of PCA, which already includes standardization. However, it is important to keep in mind the importance of this step (and to know how to do it yourself)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler(with_mean=True, with_std=True)\n",
    "df5_std = pd.DataFrame(scaler.fit_transform(df_fives))\n",
    "df6_std = pd.DataFrame(scaler.fit_transform(df_sixes))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# it is important to remember what the scaler does\n",
    "# it is safer to check that we actually managed to standardize the data\n",
    "df5_std.describe()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df6_std.describe()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Understanding what PCA does\n",
    "In this part, we will try to visualize what PCA does. For this, we will start with an \"average\" image, and progressively add PCA components. For this visualization step, we will only be using the dataframe containing the handwritten fives."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Step 1: Compute the \"average 5\"\n",
    "Create a vector (pandas Series, for example) that contains the \"mean 5\".\n",
    "Display this vector as an image. How do you interpret this ?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Your code here\n",
    "mean_5 = df_fives.mean().to_numpy()\n",
    "show_image(mean_5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Step 2: Obtain the components from PCA\n",
    "Read the code cell below. Using the documentation, explain what is done at each step."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pca = PCA()                              # the PCA object is instanced\n",
    "pca.fit(df_fives)                        # standardization, calculation of the covariance matrix, computation of its eigenvectors by SVD\n",
    "components5 = pca.components_            # returns the highest variance directions, ordered by variance\n",
    "projection5 = pca.transform(df_fives)    # returns the coefficients of the projection of the dataset over the directions given in components_"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "components5"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "projection5"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Step 3: Reconstruct an image progressively\n",
    "In this part, we will reconstruct an image from its PCA components.\n",
    "\n",
    "**Questions**:\n",
    "- Understand and explain the line marked with a question mark ❓.\n",
    "- Observe the resulting images. How many components are necessary to obtain a \"nice\" image? How do you interpret this?\n",
    "- By modifying the code below, display a reconstruction with 10 components. What do you observe?\n",
    "- By modifying the code below, try displaying other instances of the number five from the dataset."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "image_index = 3\n",
    "original_image = df_fives.iloc[image_index].to_numpy()\n",
    "show_image(original_image, \"Original image\")      # we first display the original image\n",
    "\n",
    "reconstructed_image = df_fives.mean().to_numpy()\n",
    "show_image(reconstructed_image, \"Mean image\") # then we display the mean image\n",
    "\n",
    "for i in range(0,3): # and finally we reconstruct the image using the components\n",
    "    reconstructed_image = reconstructed_image + projection5[image_index,i] * components5[i] # ❓\n",
    "    show_image(reconstructed_image, f\"Using {i+1} component{'s' if i>0 else ''}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Bonus step: Doing the same with the number 6\n",
    "Now that you understand how to use `scikit-learn`'s PCA, make the same observations with the database of number 6's."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Your code here"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "*[Your comments here]*"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Using PCA for classification\n",
    "A possible use for dimensionality reduction is to help machine learning algorithms.\n",
    "In the code cell below, we use PCA for the entire dataset (numbers 5 and 6) and store the projection coefficients in the `projection` variable.\n",
    "`df_projection` contains the same data as a `pandas` dataframe."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_unlabeled = df.drop(\"number\", inplace=False, axis=1)\n",
    "pca = PCA()\n",
    "pca.fit(df_unlabeled)\n",
    "projection = pca.transform(df_unlabeled)\n",
    "\n",
    "df_projection = pd.DataFrame(projection)\n",
    "df_projection[\"number\"] = df[\"number\"] # label the data for visualization and classification"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Questions\n",
    "- Using the code in the cell below, display a two-dimensional `scatterplot` with a different color for 5's and 6's. Which dimensions should you use?\n",
    "- What can you observe? How do you think this can help machine learning algorithms?\n",
    "- Try changing the features you display. How does the `scatterplot` change? How do you interpret this?\n",
    "- Try performing a prediction on the two-dimensional dataset. Compare the results with the baseline test on the full dataset, both in terms of accuracy and computational time. How do you interpret this?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dimension1 = 0    # should be an integer indicating which PCA component to pick\n",
    "dimension2 = 1    # should be an integer indicating which PCA component to pick\n",
    "df_two_dimensional = df_projection[[dimension1, dimension2, \"number\"]]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sns.scatterplot(data=df_two_dimensional, x=dimension1, y=dimension2, hue=\"number\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# To compare with the initial scatterplot!\n",
    "\n",
    "df.var().argmax() # returns 26, meaning the 26th pixel has high variance\n",
    "sns.scatterplot(data=df, x=26, y=27, hue=\"number\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# reminder\n",
    "run_measure_time(prediction_knn, data=df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# new results\n",
    "run_measure_time(prediction_knn, data=df_two_dimensional)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Observations\n",
    "- Slight drop in solution quality: we did lose information by only using 2 dimensions instead of 256. However, a loss of 1% in accuracy seems acceptable for a division by 128 in the number of features.\n",
    "- Somewhat significant drop in computation time: lost near a fourth of the computation time. On larger datasets with even more features and examples, this could prove significant.\n",
    "- We went from 256 to 2 variables, which makes the dataset both observable (helps with the choosing of an ML model) and less expensive storage-wise."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
