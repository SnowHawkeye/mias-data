{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Introduction to dimensionality reduction"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setup\n",
    "### Imports"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd                                     # for dataset manipulation (DataFrames)\n",
    "import numpy as np                                      # allows some mathematical operations\n",
    "import matplotlib.pyplot as plt                         # library used to display graphs\n",
    "import seaborn as sns                                   # more convenient visualisation library for dataframes\n",
    "import missingno as msno                                # utility library for missing values\n",
    "from sklearn.model_selection import train_test_split    # for classification\n",
    "from sklearn.neighbors import KNeighborsClassifier      # for classification\n",
    "from sklearn.decomposition import PCA                   # for Principal Component Analysis\n",
    "import time                                             # for execution time measurement"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Loading the dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fives = np.loadtxt(\"fives.txt\", delimiter=\",\")\n",
    "sixes = np.loadtxt(\"sixes.txt\", delimiter=\",\")\n",
    "\n",
    "# for practical reasons, we convert these arrays to a pandas dataframe\n",
    "df_fives = pd.DataFrame(fives)\n",
    "df_sixes = pd.DataFrame(sixes)\n",
    "\n",
    "# we also create a dataframe containing all numbers for later classification\n",
    "df_fives[\"number\"] = 5 # data labeling\n",
    "df_sixes[\"number\"] = 6 # data labeling\n",
    "df = pd.concat([df_fives, df_sixes], ignore_index=True)\n",
    "df_fives.drop(\"number\", inplace=True,axis=1)\n",
    "df_sixes.drop(\"number\", inplace=True,axis=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Utility functions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def show_image(row, title=\"\"):\n",
    "    \"\"\"This function takes a row of 256 pixels and displays it as a greyscale image\"\"\"\n",
    "    image = np.reshape(row, (16, 16))\n",
    "    plt.imshow(image, cmap=\"gray\")\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "def split_data(data):\n",
    "    X = data.drop(\"number\", axis=1)\n",
    "    y = data.number\n",
    "    return train_test_split(X, y,\n",
    "                            test_size=0.33,  # 10% of the data will be used for testing\n",
    "                            random_state=42,  # ensures reproducibility of the test\n",
    "                            stratify=y  # ensures the proportion of each class\n",
    "                            )\n",
    "\n",
    "def print_knn_score(scores, data_type=\"\"):\n",
    "    max_score = max(scores)\n",
    "    k_values_max_score = [i + 1 for i, v in enumerate(scores) if v == max_score]\n",
    "    print(f'Max {data_type} score {max_score * 100} % for k = {[i for i in k_values_max_score]}')\n",
    "\n",
    "def prediction_knn(data):\n",
    "    \"\"\" KNN-based classification. \"\"\"\n",
    "    X_train, X_test, y_train, y_test = split_data(data)\n",
    "    test_scores = []\n",
    "    train_scores = []\n",
    "\n",
    "    for k in range(1, 15):\n",
    "        knn = KNeighborsClassifier(k)\n",
    "        knn.fit(X_train, y_train)\n",
    "        train_scores.append(knn.score(X_train, y_train))  # \"score\" for KNN is the accuracy of the classification\n",
    "        test_scores.append(knn.score(X_test, y_test))\n",
    "\n",
    "    print_knn_score(train_scores, \"train\")\n",
    "    print_knn_score(test_scores, \"test\")\n",
    "\n",
    "def run_measure_time(function, **kwargs):\n",
    "    start_time = time.time()\n",
    "    function(**kwargs)\n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Baseline test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# equivalent to prediction_knn(data=df), but also measures time using our utility function\n",
    "run_measure_time(prediction_knn, data=df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Observing the dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "index = 0 # index of the image to show\n",
    "show_image(fives[index, :])\n",
    "show_image(sixes[index, :])\n",
    "# to do the same from a pandas dataframe\n",
    "# show_image(df_fives.iloc[0].to_numpy())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Using what you have learned in the previous lessons, examine the dataset and see what you can learn about it."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Your code here"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "*[Your comments here]*"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Principal Component Analysis (PCA)\n",
    "### Pre-processing\n",
    "\n",
    "When using PCA, it is necessary to standardize the data. Pixel values are already between -1 and 1, so we only need to center the data.\n",
    "Using what you have learned last time, center the data in `df_fives` and `df_sixes` respectively.\n",
    "\n",
    "*Hint: You can refer to the data preparation practical and use `sklearn`'s `StandardScaler`*.\n",
    "\n",
    "⚠️Centering means removing the mean value. You do not need to divide by the standard deviation. `sklearn`'s `StandardScaler`*, check its documentation to see how.\n",
    "⚠️Store the standardized data in new variables, because we will need the original data later.\n",
    "\n",
    "In fact, this step is not strictly necessary here, because we will use `sklearn`'s implementation of PCA, which already includes standardization. However, it is important to keep in mind the importance of this step (and to know how to do it yourself)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Your code here\n",
    "df5_std = ...\n",
    "df6_std = ..."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Understanding what PCA does\n",
    "In this part, we will try to visualize what PCA does. For this, we will start with an \"average\" image, and progressively add PCA components. For this visualization step, we will only be using the dataframe containing the handwritten fives."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Step 1: Compute the \"average 5\"\n",
    "Create a vector (pandas Series, for example) that contains the \"mean 5\".\n",
    "Display this vector as an image. How do you interpret this ?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Your code here"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Step 2: Obtain the components from PCA\n",
    "Read the code cell below. Using the documentation, explain what is done at each step."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pca = PCA()                              # your comment here\n",
    "pca.fit(df_fives)                        # ...\n",
    "components5 = pca.components_            # ...\n",
    "projection5 = pca.transform(df_fives)    # ..."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Step 3: Reconstruct an image progressively\n",
    "In this part, we will reconstruct an image from its PCA components.\n",
    "\n",
    "**Questions**:\n",
    "- Understand and explain the line marked with a question mark ❓.\n",
    "- Observe the resulting images. How many components are necessary to obtain a \"nice\" image? How do you interpret this?\n",
    "- By modifying the code below, display a reconstruction with 10 components. What do you observe?\n",
    "- By modifying the code below, try displaying other instances of the number five from the dataset."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "image_index = 3\n",
    "original_image = df_fives.iloc[image_index].to_numpy()\n",
    "show_image(original_image, \"Original image\")      # we first display the original image\n",
    "\n",
    "reconstructed_image = df_fives.mean().to_numpy()\n",
    "show_image(reconstructed_image, \"Mean image\") # then we display the mean image\n",
    "\n",
    "for i in range(0,3): # and finally we reconstruct the image using the components\n",
    "    reconstructed_image = reconstructed_image + projection5[image_index,i] * components5[i] # ❓\n",
    "    show_image(reconstructed_image, f\"Using {i+1} component{'s' if i>0 else ''}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Bonus step: Doing the same with the number 6\n",
    "Now that you understand how to use `scikit-learn`'s PCA, make the same observations with the database of number 6's."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Your code here"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "*[Your comments here]*"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Using PCA for classification\n",
    "A possible use for dimensionality reduction is to help machine learning algorithms.\n",
    "In the code cell below, we use PCA for the entire dataset (numbers 5 and 6) and store the projection coefficients in the `projection` variable.\n",
    "`df_projection` contains the same data as a `pandas` dataframe."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_unlabeled = df.drop(\"number\", inplace=False, axis=1)\n",
    "pca = PCA()\n",
    "pca.fit(df_unlabeled)\n",
    "projection = pca.transform(df_unlabeled)\n",
    "\n",
    "df_projection = pd.DataFrame(projection)\n",
    "df_projection[\"number\"] = df[\"number\"] # label the data for visualization and classification"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Questions\n",
    "- Using the code in the cell below, display a two-dimensional `scatterplot` with a different color for 5's and 6's. Which dimensions should you use?\n",
    "- What can you observe? How do you think this can help machine learning algorithms?\n",
    "- Try changing the features you display. How does the `scatterplot` change? How do you interpret this?\n",
    "- Try performing a prediction on the two-dimensional dataset. Compare the results with the baseline test on the full dataset, both in terms of accuracy and computational time. How do you interpret this?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dimension1 = 0    # should be an integer indicating which PCA component to pick\n",
    "dimension2 = 1    # should be an integer indicating which PCA component to pick\n",
    "df_two_dimensional = df_projection[[dimension1, dimension2, \"number\"]]\n",
    "\n",
    "# Your code here"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "*[Your comments here]*"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
